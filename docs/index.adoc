= Audience Participation
Florian Jung
v0.1.2, 2015-04-19
:doctype: book
:encoding: utf-8
:lang: en
:toc: left
:sectnums:
:chapter-label:
:pdf-page-size: A4
:stem: latexmath
ifdef::env-github,env-browser[:outfilesuffix: .adoc]

:toc:




== Overview



=== History
It all started with a single lecture. The students were tasked with imagining
ways to include the audience into a live performance. Based on that simple instruction
sprung forth from the creative mind of my colleague Angelika Fürndraht-Grossschopf
a very interesting idea: +
[quote, Angelika Fürndraht-Grossschopf]
“Why don't we let the people influence the performance by standing up or sitting
down? Not only do they get to participate in a potentially really fun way, they
would be exercising at the same time!”

That thought finally grew to become the foundation of this bachelor thesis. She
partnered with another student who was going to design the software component. +
A couple weeks after they began their work on a first draft of the thesis proposal,
I heard of this idea for the first time. I was immediately fascinated by their project.
It was not only the integration of the auditor with a potentially game like scenario,
but the complexities of recognizing people's movements, transmitting these actions
to a central point and then reacting to that information what caught my interest
as a programmer and tinkerer. So it comes as no surprise that when Mrs Fürndraht-Grossschopf's
original partner quit the project, I did not hesitate to jump on the opportunity
to work with her.



=== Initial project specification
The project's domain is a theatre like placement. The two major stakeholders, one
artist and the audience, consisting of several, possibly up to hundreds of members,
are placed opposite from each other. The listeners' seats are spread over several
rows facing mostly in the same direction towards the performer. She will prepare
beforehand a composition, prerecorded and split into separate tracks, one for the
basic theme and several instruments on their own. +
The basic theme will play in the background during the whole performance, whilst
the audience is able to control the influence selected instruments have on the aggregated
musical experience. The interface to communicate their intentions is a seat-occupancy-sensor.
By standing up or sitting down they can decide what should happen. +
During the live performance the artist primarily inhabits the role of conductor.
She first divides the people into different groups, each linked to a specific instrument.
The percentage of people standing in such a cluster directly influences how loud
an instrument plays. For example, if 10 people of the guitar group consisting of 20
were to stand up, would result in the guitar playing at half the maximum volume. +
She further needs to explain to the audience how they are able to affect the rendition
and the role sectioning plays. In the beginning stages she will also direct the
rising and sitting to accustom the participants to the interaction and the system
as a whole. +
Later she might allow the people to freely create their own music by deciding the
active instruments by themselves.



=== Research questions
*What processing speed can be determined to be sensible and how can the design be
optimised to reach that minimum update rate?*

By assessing the flow of information from the audience member to the artist at the
front, I will identify weakpoints and bottlenecks. Further, I will try to eliminate
them or establish acceptable limits for performance ranges through careful reflection
to attempt to at least mitigate them. Simple tests will then aid in the evaluation
of the established guidelines.


*Which factors and challenges have to be considered when selecting hardware components
to build a flexible, cost efficient system to facilitate audience participation
using seat sensors?*

I will analyse several different technologies in regards to their ability to recognise
the “standing up”/”sitting down” actions, practicability and building costs. Deciding
factors will include how easy a sensor is to construct and deploy, as well as its
accuracy. The price range of the sensor itself should be limited to about 20 to
30 euros. However, to further accelerate the experimentation process, usage of off-the-shelf
parts or components already available in most households, should be taken
into consideration.



=== Related Works
This section describes related papers in the field of audience participation, focusing
on practical implications and implementations.

Barkhuus and Jørgensen _[1]_ developed a 'cheering meter' to simplify the voting
procedure at rap competitions. Because of daily assembly and disassembly they deployed
their in Java written software on a laptop connected to 4 microphones pointed at
the audience. The captured sound was then analysed for peak levels of cheering and
the winner selected based on the highest registered value. Though utilising an entirely
different form of interaction, they share our sentiment of not using phones (text
messages) and rely instead on a more physically involving type (cheering).

Paradiso et. Al _[2]_ examined the possibilities of giveaway wireless motion sensors.
The sensors transmit “a short pulse of RF energy” to a base station “whenever they
encounter a dynamic acceleration greater than a predetermined level”. With a very
small form factor (6.2 cm x 1.6 cm x 1.0 cm) and a weight of 5 grams they can be
easily held or worn. The low power consumption allows a 3V lithium coin cell battery
to operate a time of 3 to 4 years in normal use (“assuming one event/week”). Though
the system seems to handle larger crowds of 200 people well, the transmission design
does not permit the distinction between different devices beyond a crude grouping
(here 3 groups) which has to be set at hardware level. +
The proposed responsive and dynamic music generation is in some ways similar to
our approach of using several tracks simultaneously. They, however, model continuous
activity in the form of dancing to five general activity levels, while we associate
a groups' state (standing/sitting) with instrument (track) volume. +
Though the low cost and power consumption make for an intriguing design, the sensor
is not suited for our purposes. The grouping based on trimmer capacitors is too
inflexible and coarse. Further, it would have to be determined whether exceeding
a certain dynamic acceleration level is a sufficient enough indicator for the activities
'standing up' and 'sitting down'.

With massMobile, Weitzner et al _[3]_ have created “a client-server system for mass
audience participation in live performances using smartphones”. Special focus was
put on ease of setup, development of additional use cases and deployment. To support
multiple platforms, they utilise a web application executed in a phone's
browser connected to a custom API. +
The framework comes with its goals of “rapid deployment..plug-and-play deployment..
and simple use” close to our intentions for our project. Nonetheless, there is
room for improvement in regards to latency. The network traffic could be significantly
reduced by switching from the TCP based SOAP to an UDP alternative. For reasons
which get explored more in depth below, we dislike the idea of mobile phones being
the primary form of input.


_[1] BARKHUUS, Louise; JØRGENSEN, Tobias. Engaging the crowd: studies of audience-performer interaction. In: CHI'08 extended abstracts on Human factors in computing systems. ACM, 2008._ +
_[2] PARADISO, Joseph A.; FELDMEIER, Mark. A compact, wireless, self-powered pushbutton controller. In: Ubicomp 2001: Ubiquitous Computing. Springer Berlin Heidelberg, 2001. S. 299-304._ +
_[3] WEITZNER, Nathan, et al. massMobile-an Audience Participation Framework. In: NIME. 2012. S. 21-23_ +



=== Goals and considerations
Based on the research questions and the initial research we established fundamental
properties the design should incorporate:

First and foremost should the project be published under an open source license.
We have found that very few authors publish anything beyond the paper itself and
rarely make the accompanying code available. Nonetheless, we believe it to be important
to share more than just the guiding principle behind an idea, but an implementation
as well. This makes it easier for others to both reproduce the described results
for themselves and enable them to experiment further with a minimum amount of prior
work. +
Ease of use should also be kept in mind. A framework only truly becomes practical
when it is convenient to set up and deploy. Likewise, should the code be kept simple
and readable. +
Extendibility is a priority goal for this project. Although it is developed with a
specific use case in mind, it should be easy to add other scenarios to maximise
the benefits for others. This shall be achieved by clear and uniform interfaces allowing
mixing and extending as needed. If possible the components should not be too specific
in their function, potentially freeing them of the context of this framework and
letting them be used in other projects. +
Having a fast feedback loop is important. After all, it is not very rewarding if
you take an action and something happens only 1 minute later. The user can not effectively
asses the connection between her activity and the systems reaction. Furthermore,
if you have ever watched a video of a person speaking and the audio was offset even
by for example 50 ms - the difference was noticeable. It stands to reason that delays
might be as obvious in music, making latency and speed a crucial factor. On the
other hand, the process of standing up is inherently imprecise. You have your inert
body to put into motion and at the same time are unaware at which point exactly
is the seat sensor going to trigger. There is no individual feedback which would allow a person
to attempt to compensate for the delay. +
For this reasons a compromise is needed: Though design should consider speed, ideally
creating a realtime system, a margin of error (e.g. maximum of 1 second) shall be
allowed. This creates leeway for the implementation and can account for the inaccuracy
of the interaction itself. +
The framework should not have to handle millions of users at a time, relying
on technologies like load-balancers, but it should scale from an audience of only
a handful up to at least a hundred people. +
Several diverse reasons lead to the decision against the implementation of a mobile
phone based system. It is true that smartphones have become a wide spread, almost
ubiquitous, commodity, but relying on them would potentially exclude some users with
e.g. older phones. Even when owning a brand new, top of the line smartphone, problems
may arise. A guest may arrive with an empty battery. The app may have a high power
consumption, leaving the phone completely discharged after the performance, resulting
in inconveniences and low customer satisfaction. +
Furthermore, the difficulty of supporting multiple mobile operating systems should be
considered. There exist solutions to cover different platforms with a single code
base (link:https://cordova.apache.org/[cordova]), but device API access and potential
performance limitations should be minded.
Another concern is the deployment method. Since installation should be as easy as
possible, using the platforms' native app stores would be the straight forward and
preferred way. This, however, requires being part of a priced development program in
most cases (99 $ in link:https://developer.apple.com/support/compare-memberships/[Apple's case]),
which may not be cost-efficient in some use cases. +
Ideally, the technology to facilitate the interaction should be as unintrusive and
unnoticeable as possible. +
Another important goal is affordability. To cater to a large and diverse developer
base, including researches, students, etc., a tight budget should be assumed. Complicated
and expensive hardware should not be necessary to execute the software. Nor should
the seating state sensing require a pricey sensor.



=== Technology
==== Computing platform
As the basis for the occupancy sensor we chose a Raspberry Pi _[4]_. The Raspberry Pi
Foundation offers several different models ranging in price from the small Pi Zero
at 5$ up to the Pi 3 at 35$. The big advantage of a Pi over a simple micro-controller
like an Arduino is the ability to run a full-fledged operating system. These include
Windows IoT and Raspbian, a Debian-based custom system, developed and maintained
by the Foundation, which is what we selected. We decided on a Pi 2 because of the builtin
ethernet port and the 900 MHz quad-core ARM Cortex-A7 CPU suppling more than
enough computing power to run the sensor software.

_[4] https://www.raspberrypi.org/help/faqs/, last accessed 2016-04-15_


==== Sensing
To detect the actual person sitting in the chair, we settled on a force-sensitive
resistor (FSR). The relative low price, the easy and wide range of deployability
being the deciding factors. Dimensions of about 4,5cm x 4,5cm make it possible to place
it on any kind of chair whilst being hardly noticeable.

image::sensor_with_pi.jpg[caption="Figure 1: ", title="Sensor and Pi", width="500"]

To increase comfort and simulate possible real world scenarios, we tried to put
the sensor under a cushion. Our experiments have shown it to work regardless.
This setup has the additional benefit of hiding not only the sensor itself, but
also the cable connecting to it. +
Although we were able to acquire such a sensor for about 10€ [5], there are even
cheaper alternatives. Nassar et al [6] have shown that such a sensor could be constructed from
everyday household objects with little effort. +
Since the Pi is not equipped with digital inputs, we needed an additional board to
transform the varying resistance of the sensor to binary inputs. Here we utilized
a little trick. The voltage level of the General Purpose Input & Output (GPIO) pins
are between 0 and 3.3 V maximum. The Pi, however, recognizes everything upwards of
about 1.3V as a logic 'HIGH'. The obvious solution was to use a voltage divider.

image::voltage_divider.jpg[caption="Figure 2: ", title="Voltage Divider"]

The V [small]#+# connects to the 3.3V and V [small]#out# to an arbitrary input line
on the Pi. +
Using a one kiloohm resistor (R), we calculated the force-sensitive resistor to pass
the 1.3 volt marker at approximately 1.5 kiloohm, which corresponds to about 800g
applied weight. _[7]_ In our tests this has proven to be remarkable reliable. +
We further built two boards which are able to use four and five force-sensitive resistors
simultaneously.

image::board_front.jpg[caption="Figure 3: ", title="Board front view", width="500"]

image::board_side.jpg[caption="Figure 4: ", title="Board side view", width="500"]

image::board_with_sensor.jpg[caption="Figure 5: ", title="Board with sensor", width="500"]

Since each sensor requires only one GPIO pin to work,
a single Pi would be able to support over 15 resistors. However, every sensor needs to
be connected to the board. Increased cable length also potentially increases power
consumption and complexity of the cable management. So to not overtax the Pi's limited
power capabilities, we limited the number of available connections on the board.
We recommend using an uneven number and place the small computer with the
middle seat. The cables can then be run to either side.

_[5] http://www.amazon.de/gp/product/B004R277AS/, last accessed 2016-04-15_
_[6] NASSAR, Joanna M., et al. Paper Skin Multisensory Platform for Simultaneous Environmental Monitoring. Advanced Materials Technologies, 2016._
_[7] https://www.sparkfun.com/datasheets/Sensors/Pressure/fsrguide.pdf, last accessed 2016-04-18_

==== Name
The name of the core python software is based on the project title *paps*
(*P* i-based *A* udience *P* articipation *S* ystem). However, if you
are not going to use a Raspberry Pi in your project, *paps* once more applies
(*P* ython-based *A* udience *P* articipation *S* ystem). If you want to go even
further and for example use only the interfaces and/or the network protocol, *paps*
still works (*PA* rtici *P* ation  *S* ystem). +




== Installation
=== Environment
All the code is written in python 2, specifically version 2.7. Parallel support
for python 3 is a work in progress. +
Windows has been primarily used for development of the main components and Raspbian
Jessy for the sensor code.



=== Basic installation
The first thing you need, is a working python environment:

* Install the latest version of link:https://www.python.org/downloads/[python 2.7]
* Install/get the latest version of link:https://pip.pypa.io/en/stable/installing/[pip]

.RECOMMENDED
[NOTE]
We recommend working on and running your code in a virtual environment. +
You can use link:https://virtualenv.pypa.io/en/latest/[virtualenv]



=== Paps installation
==== PyPI
If you want to use paps in your own project, it is available from link:https://pypi.python.org/pypi[PyPI]. +
Simply install it via `pip install paps` or add paps to your requirements file.


==== Manual/Github
Get the latest version from link:https://github.com/the01/python-paps[github] and
run `python setup.py install`. That installs every dependency and you are good to go.



=== Paps development
If you want to work on paps and develop it further, use the `Manual/Github` installation
method, but change `python setup.py install` to `python setup.py develop`. That
way any changes you make take effect immediately. We also recommend installing the
development-dependencies ( `pip install -r dev-requirements.txt`. +
Finally, do not forget to send us a pull request.




== System
=== Core concepts
==== Person
Although paps was developed in the context of a musical project, it is designed
as a general audience participation framework, not limited to a single use case. +
Naturally, the core entity used throughout the system is creatively called `Person`.
It represents an audience member and her current state. +
At this point a Person only has two properties, an id and a field to indicate whether
the represented individual is standing up or sitting down. However, as long as all
the transform functions (to_/from_dict, to_/from_bits,..) in
link:https://github.com/the01/python-paps/blob/master/paps/person.py[person.py]
are changed, paps itself should continue to work as expected (the SensorServer might
need a few adjustments). Keep in mind that not every plugin (see later) might be
as lenient in the type of Person it can work with.


==== Flotils
Most classes inherit in one way or the other from the link:https://github.com/the01/python-flotils[flotils]
package. Most notable are the `Logable` and `StartStopable` classes. `Logable` adds
logging capabilities to an instance (as best demonstrated on the above github page).
`StartStopable`, as the name suggests, provides methods to start and stop a class
instance. Calling start with `True` as the parameter is blocking, which means it will
only return after stop has been executed. Additionally it provides a boolean variable
indicating its current state (running or not).


==== ChangeInterface
The other core concept besides a Person is the
link:https://github.com/the01/python-paps/blob/master/paps/changeInterface.py[`ChangeInterface`].
It represents the most generic actions a person can take:

* *on_person_new*: This occurs when a person has just joined the audience. In other
  words she was not known to the receiving component before.
* *on_person_update*: The state of a person has actually changed. (No person for
  whom that is not true should be included here)
* *on_person_leave*: A person has left the audience and should not be minded
  from this moment forward.

The ChangeInterface is mostly used at borders between different layers of the system
(physical sensors detecting actual humans, the SensorServer receiving events from
clients, the CrowdController forwarding changes, ..). +
It is recommended to use/implement whenever Person information needs to be exchanged.



=== Crowd
Crowd represents the highest level of the paps framework. All levels below are responsible
for people recognition (data acquisition), transmission and management. This stage
is where the audience participation actually takes place. +


==== Plugin
The plugin is the component that accomplishes exactly that. Here you would
write the code for your base-performance and react to changes/movement in your audience. +
One possible plugin could implement the logic for musical chairs. You would place
sensors on every seat and the plugin would start playing music. At some random point
the music would stop and the last one left standing would be eliminated. You could even
have a ranking or statistics on who was the fastest to sit down or cheated. +
A plugin can be run since it inherits from StartStopable and receives information
about the audience by implementing the ChangeInterface. +
Additionally a `controller` property is present, which is `None` by default, except
when executed by a CrowdController (see next part). +
Because it is able to receive change-events, it is possible to directly put a plugin
on top of a sensor, bypassing network components (see SensorInterface). +
When writing a plugin one should keep in mind that method invocations might block
the calling code. For example time spent inside `on_person_update` should be kept
as short as possible, otherwise the sensor or server might miss updates on the audience's
state.


==== CrowdController
In practice it is a good idea for classes between different layers to be loosely-coupled.
An instance wanting to emit change-events should only have to use a ChangeInterface.
But that means one were only able to use a single plugin at the same time. On the other
hand it could utilize multiple ChangeInterface-objects, but would also have to
implement management code for all those instances, unnecessarily complicating
the class. +
That is where the CrowdController comes in. It has a `plugins` property, where multiple
plugins can be registered. Since CrowdController is a subclass of Plugin, it can
be used everywhere you would normally use a plugin (or ChangeInterface for that
matter). Every method call on the controller is forwarded to each plugin, including
`stop()` and `start()` (which is where the plugin's `controller` property is set). +
The recommendation about keeping execution time short becomes especially critical
when using a CrowdController with multiple plugins. It would be possible to dispatch
all method-forwards to their own thread. Currently, the controller only iterates
through the plugins, sequentially calling the methods. As a result the sensor/server
gets blocked for the sum of the individual execution durations. Even if your
plugin returns in 0.2 seconds, using 5 such plugins simultaneously would still result
in a time lag of a whole second.



=== Communication
The first step was to decide how the different sensors would be communicating with
the server. Ease of installation and avoiding extra components being primary concerns,
we decided on Local Area Network (LAN). Most Raspberry Pis come equipped with an ethernet port.
This was before the Pi 3 was announced on February 29th 2016 _[4]_, which offers onboard
WIFI as well as Bluetooth. We would have still settled on using LAN, because of the higher
transfer rates and stability. +
The downside of course being, that now every sensor has to be connected to the
network via cable. On the other hand one could eliminate the power cable by using
power over ethernet (PoE) and an adapter.


==== SensorInterface (si)
The sensor interface is responsible for connecting sensors monitoring the actual
people in the audience to the plugin(s) running the participation related code.
An implementation should link the two parts of the interface (client/server) together
(for example over LAN). +
It is recommended for sensors to propagate their information to an other object
by use of the ChangeInterface. That way, when testing or using a simple setup, a
user can connect a plugin or CrowdController directly to the sensor and does not
have to go through a network component first. +
An example of such a sensor software has been provided with paps and can be found in the
link:https://github.com/the01/python-paps/blob/master/examples/gpio_detector.py[example directory].
This GPIODetector monitors specified GPIO pins on a Raspberry Pi for changes, where
a set (HIGH) pin represents a sitting and an unset (LOW) pin a standing person. +
The example further demonstrates how to save/load a configuration from a file with
the main focus being the device id (see APP in the next chapter) and how to connect
a sensor to the SensorInterface (SensorClientInterface).

===== SensorClientInterface
The SensorClientInterface is heavily inspired by the ChangeInterface, but amended
with remote configuration capabilities. Its `config` method should be implemented
to allow the server to alter local settings (potentially including higher layers,
that use the SensorClientInterface). +
Though still holding much of the same meaning, the on_person-events have been renamed
for this interface.

* on_person_new ≈ join
* on_person_leave ≈ unjoin
* on_person_update ≈ person_update

This decision was taken deliberately for two reason. The ChangeInterface's methods
are passive, that is to say, you receive information. The SensorClient's on the
other hand are active. You tell someone else that something has changed. Secondly,
this was chosen to reflect the different scale. The communication between SensorClient
and SensorServer is meant to bring the state-information of the whole audience together.
You are not only detecting a new person, but rather a new person has joined the
audience.

===== SensorServerInterface
The SensorClientInterface's counterpart is responsible for translating the incoming
information back into change-events. It takes a `change` argument in its constructor
that has to implement the  ChangeInterface and will receive the events.

===== SensorServerClientAdapter
Since connecting a sensor to a SensorClientInterface implementation is probably
a very frequent task, paps has such an adapter already built in. Give the SensorClientAdapter
an instance of a SensorClientInterface and then plug the adapter (it implements
the ChangeInterface) into your sensor and change-events will be translated into
SensorInterface-actions.


==== Audience Participation Protocol (APP)
Keeping the project goals in mind and wanting to keep the network traffic as low
as possible, we decided to design our own protocol. +
TCP as the basis would be easy. It guaranties reliable, correct and ordered packet
delivery. Definitely good properties for a protocol to have. +
Since People coming/leaving (in the context of ChangeInterface) only happens at
the beginning/end, most of the traffic will consist of update events. Keeping hundreds
of TCP connections (and sockets) open for that single purpose seems unpractical,
which is why we opted for a UDP-based protocol.

[NOTE]
The protocol uses big-endian encoding.

===== APP Header
image::appheader.svg[caption="Figure 6: ", title="APP header", width="500"]

*Protocol field* (C Type): Description of field

*Version* (unsigned char)
*Maj Ver* (nibble): Major part of protocol version

*Min Ver* (nibble): Minor part of protocol version

*MsgType* (unsigned char): Message Type/type of packet

* 0: (ACK) Empty packet - only acknowledging packet
* 1: JOIN-Packet
* 2: CONFIG-Packet
* 3: UNJOIN-Packet
* 4: UPDATE-Packet
* 5: DATA-Packet

*Payload Length* (unsigned short): Length of the payload (in bytes)

*Timestamp* (float): Unix timestamp of packet creation/transmit time

*Device Id* (unsigned short): Device id of sender.

* 0: (REQUEST) Request a new id from server
* 1: (SERVER) Id of a server.
* 2-65536: Possible client id

*Flags* (unsigned short): Set flags. To use several in the same packet either add
the values or do a bit-wise or.

* 1: (SEQ) Is a sequence number present
* 2: (ACKSEQ) Is an acknowledged sequence number present

*Sequence Number* (optional)(unsigned int): Sequence number of packet. If present,
SEQ flag has to be set. If present, requires an ACK to be sent. +
By using this you can ensure packet delivery.

*ACK Sequence Number* (optional)(unsigned int): Acknowledge for packet with this
Sequence Number. If present, ACKSEQ flag has to be set. +
A dedicated ACK-Packet is not needed. By setting this field, any packet can become
an ACK-Packet.

*Payload* (Payload Length number of bytes): Payload content is dependent on the
type of packet/message being transmitted

===== APP JOIN Message
Message to join the local audience and comparable to `ChangeInterface.on_person_new`.
This can be sent to the server directly or, to enable auto-discovery capabilities,
to a multicast group (Recommended: 239.255.136.245). Of course a server first has
to make a membership request for that group. +
The payload consists of a string with a json object containing all information
required to join the audience. The absolute minimum is a field `people` with an
array of the people (Person) this client offers as a json object (python dict)
encoded (see following code). Additional fields may be added as needed, but are
not part of the APP specification. +
APP requires that all the people have to be announced at join-time. If you want
to add people at a later point, unjoin first and then re-join with the updated
people list. +
The `device id` field of the header may be either set to REQUEST (0) or to a valid
client id (2-65536). Providing a client id much like with DHCP only serves as a
request for that id, the server can choose to assign a different one. The logic
on how to handle id collisions and to identify clients between runs is left to the
concrete implementation. Though some possible approaches could involve MAC-addresses
or issuing unique ids.

[source, json]
----
  {
    "people":[Object representation of Person]
  }
----

Requires an ACK-Packet to be sent.

===== APP CONFIG Message
Message to change the configuration (of a client). +
The payload consists of a string with a json object containing all configuration
changes. If a settings parameter is not present, it should not be changed. +
The parameter names can be chosen freely (in accordance with json), except for these
reserved ones:

* device_id: New device id assigned to this client
* server_ip: The IP where the server can be reached. (Auto-discovery over multicast is deeply integrated into APP -  though not required)
* server_port: The port where the server can be reached.

Requires an ACK-Packet to be sent.

===== APP UNJOIN Message
Message to leave to local audience and comparable to `ChangeInterface.on_person_leave`. +
Informs the server that all people associated with this client are leaving the audience. +
This packet does not have any kind of payload, which means the server has to keep
track of who (people) are registered with this client.

Requires an ACK-Packet to be sent.

===== APP UPDATE Message
Message to update the state of people and comparable to `ChangeInterface.on_person_update`. +
Since this is most frequently, concurrently sent packet, most of speed and
size considerations were taken here. It does NOT require an ACK-Packet to be sent,
cutting the number of packets in halve. However, APP is still based on UDP,
so packet loss is a possibility. To address this, every UPDATE message needs to
contain the state of ALL people being monitored by this client. This reduces the
chance of lost information especially under the following assumptions:

. A single client monitors not just one person, but multiple.
. People seated closely together, move together. If the person next to you stands
  up, you are likely to move as well.
. People are placed together in few groups.
. It only matters for a group how *many* people are in a certain state, not which
  ones.

Following these assumptions, consider this thought experiment: +
You and the two people sitting to your left and right are in the same group
(your actions have the same result), as well as your seat sensors being connected
to the same client (Raspberry Pi) [assumption 1]. Lets visualize that state in the
following way *[seated, seated, seated]*. +
Now the person on your left stands up, changing the simple overview to *[standing, seated, seated]*
and triggering the client to send this change to the server. Next you and then your
other neighbour stand up [assumption 2]. This does not necessarily have something
to do with herd mentality, but maybe the conductor has told your group to stand up.
The state changes to *[standing, standing, seated]* and finally *[standing, standing, standing]*.
These changes also get transmitted to the server. +
Even if the first two packets in this scenario were lost, as soon as the third arrived
at the server, it would have the complete and correct state of your group (at least
the ones connected to your client). It would get that information a little
later, but we have cut the traffic by 5 packets (1 x resent UPDATE-packet
& 1 x ACK-Packet for each of the two lost packets + 1 x ACK-packet for the last
UPDATE that did not get lost) +
If, however, the first and last packets were lost, then the information about your
right neighbour standing up would not have reached the server. +
But if you consider that UDP-packets are more likely to be dropped with

.. bigger packet sizes +
.. more packets on the network

you can look at strategies to decrease the chances/impact. _[8]_ +
Lets consider b). More packets mean more people (updates), which also means either
packet loss is less/not very likely or we have many people. We do not have a problem
in the first case and in the second, only a few people will have wrong state
information (see example scenario above). Because of [assumption 3] group sizes
will be big, but because of that and [assumption 4], a single (or few) person being
misrepresented will not have much negative impact on the group as a whole. +
a) is also being addressed by APP. A person implements transformation functions
to and from a bit-representation. Currently this only consists of the sitting-state: +
`0` = is not sitting; `1` = is sitting. +
Since the UPDATE-packet requires the state of all people be present in the payload,
the device id can be omitted, but the same order as in the JOIN-packet has to be
kept to still be able to identify each person. +
The bit-representation then gets packed into bytes and the information start indicated
by a marker (`1`) +

====== Examples
`P(0,sit)` means a Person with id = 0 is sitting +
`P(1,!sit)` means a Person with id = 1 is not sitting

|===
|Name of Column 1 |Bit representation |Hex representation

|`P(0,!sit)`
|10
|0x02

|`P(1,!sit)`
|10
|0x02

|`P(0,sit)`
|11
|0x03

|`P(0,!sit);P(1,sit)`
|101
|0x05

|`P(0,!sit);P(1,!sit);P(2,sit);P(3,!sit);P(4,sit);P(5,!sit);P(6,sit)`
|1001 0101
|0x95

|`P(0,!sit);P(1,!sit);P(2,sit);P(3,!sit);P(4,sit);P(5,!sit);P(6,sit);P(7,sit)`
|1 0010 1011
|0x012b
|===

_[8] SAWASHIMA, Hidenari, et al. Characteristics of UDP packet loss: Effect of tcp traffic. In: Proceedings of INET’97: The Seventh Annual Conference of the Internet Society. 1997._

===== APP DATA Message
A DATA message enables the protocol to transmit data as a json encoded
string.

Requires an ACK-Packet to be sent.




== Conclusion
=== Reflection on research questions
The first problem I encountered when exploring speed related aspects was with the
audience interaction method itself. I argued that because of the big movement of
standing up/sitting down and the user's inability to determine exactly at which
point in the movement the sensor registers a change, the participant's signal is
inherently inaccurate to some degree. An example demonstrated how even a slight
audio offset is still noticeable to humans. I then reasoned that requiring such
precise timing is not only not possible, but also not necessary, since an individual's
actions are not directly traceable by her. Only the groups aggregated influence is visible.
Therefore, I concluded that a certain margin of error has to be allowed. +
I decided the best option to connect the sensors to a central server would be with
a custom UDP protocol. I explained its network traffic reducing capabilities, weighed
the risks of information loss and finally established that the built-in resilience
either sufficiently protects against this failure or renders its influence insignificant.
Several tests confirmed this. Furthermore, they indicated a processing power of
200 to 400 update packets per second depending on the machine and approximately
50 milliseconds for a complete roundtrip of an update packet. This not only shows
the system performs within the allowed margin of error, but also almost approaches
realtime capabilities. The deciding factor then becomes the implementation of the
plugin working with the information. Not only does its processing speed influence
how fast changes in e.g. the music can be realised, but also how fast and reliably
the underlying modules are able to work. The receiving of change-events in a plugin
blocks the calling code. This small deficiency was accepted in favour of avoiding
additional complexities inside the network modules. If, however, speed ups become
vital, python easily allows the integration of external code written in C. That
way critical sections can be rewritten using this much faster language while still
keeping remaining parts as they are. As exhibited, python has thus far proven satisfying
in its execution speed.

I examined several different technologies for their merits as part of this audience
participation system. Some, like mobile phones, were excluded, because they would
have unnecessarily slowed the system down, thus violating the goal of the first research
question. Others would not have been accurate enough in their person state determination.
Such considerations finally led to the force-sensitive resistor, which fulfils all
previously established requirements. It can be easily placed on any kind of seat
and achieves practically a hundred percent accuracy. Even under difficult circumstances
like placing a cushion on top, it performs flawlessly. The price of 10€ might be
considered a bit high, but our research has shown that it is possible to construct
a force sensor from everyday household items, likely reducing costs further. +
The decision for the connecting component, the LAN, was taken based on its ability
to unproblematically scale, provided infrastructure like cables and switches are
available. Additionally  it is already present in most homes and offices, following
the set mandate to focus on technologies readily available in a typical household.
By using LAN, problems like interference with radio-based communication channels
can be avoided. +
The selection of a Raspberry Pi as the software platform might be considered a breach
of the research goal. Some microcontrollers like an Arduino would have costed significantly
less, probably provided enough computing power to execute the sensor-control-software
and would not have needed a supplementary board to connect to the force-sensitive
resistor. I argue that the Pi still fulfils all listed criteria. The extra board
consists solely of wires and resistors, which should cost less than one euro and
be something most hobbyist has at home. Assuming a board for five sensors, the proportional
price of the Pi-electronics combination would come to about 8 euros per seat, which
is well inside the established budget of 20 to 30 euros. The real advantage the
Pi has over the microcontroller alternatives, is its usage as a platform for experiments.
Not only does it offer various hardware interfaces, it also has all the benefits
of a full-fledged computer and Linux operating system. This allowed me to freely
test different technologies and approaches without having to commit to one.



=== General observations
The well documented and commented source code results in good readability.
Someone new to the codebase, but familiar with the general components of paps and/or
this document, should be able to understand the different parts quickly
and start developing without any difficulties. The python programming language,
which except for a few peculiarities allows for a straightforward way to write code,
further aids this. +
The server auto-discovery of the audience participation protocol in combination with
the ability to save runtime settings between executions, such as the device id, which is
demonstrated in GPIODetector, make deployment easy, even to a large number of sensors.
Only a single SD card needs to be prepared where the software is set to automatically
run at boot-time and the seats need to be allocated to the specific groups only once.
Though the interface was designed to run in a web browser to control the system
from a variety of devices including tablets, the sorting remains a tedious errand.
There is only a demonstration implementation available, showing one possible way of approaching
this task and will most likely prove to work best with only few people.
Identifying which physical sensor corresponds to a person in the interface has to
be achieved by manually triggering the sensor.
Of course, this method does not scale well to an audience size of hundreds of people. But since
it only needs to be done once, it might be considered an acceptable complication. +
The uniform interfaces, especially `ChangeInterface`, make for a very modular implementation,
allowing to freely combine different parts of the application (e.g. using a plugin
with or without a CrowdController, placing a plugin directly on top of a sensor,
etc.). Additionally, the design of the APP enables the developer to easily connect
to the included `SensorServer` from her own modules and even different programming
languages. Still, it was designed with a certain environment and simplicity in mind.
The network is imagined to be only accessible to APP devices, with no malicious
clients and minimal other traffic. The result is a very naïve protocol with
few control, authentication or security features built in. It is also very
susceptible to denial of service attacks and tampering, both intentional and unintentional.
That is adequate according to our predefined constraints, but should be kept in
mind when actually deploying the system. +



=== Final remarks
With my work I was able to create an application, both in hardware and in software,
letting audience members influence the execution of prerecorded music and change
the volume and dominance of specific instruments. I further built a core framework
for general audience participation, laying a foundation for different interaction
methods. +
This system moreover satisfies all set design goals within their constraints, including
performance, construction cost, modularity and manageability.


== How to
include::write_plugin.adoc[leveloffset=+2]

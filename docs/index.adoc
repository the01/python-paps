= Audience Participation
Florian Jung
v0.1.0, 2015-04-15
:doctype: book
:encoding: utf-8
:lang: en
:toc: left
:sectnums:
:chapter-label:
:pdf-page-size: A4
:stem: latexmath
ifdef::env-github,env-browser[:outfilesuffix: .adoc]

:toc:




== Overview



=== History
It all started with a single single lecture. The students were tasked with imagining
ways to include the audience into a live performance. Based on that simple instruction
sprung forth from the creative mind of my colleague Angelika Fürndraht-Grossschopf
a very interesting idea: +
[quote, Angelika Fürndraht-Grossschopf]
“Why don't we let the people influence the performance by standing up or sitting
down? Not only do they get to participate in a potentially really fun way, they
would be exercising at the same time!”

That thought finally grew to become the foundation of this bachelor thesis. She
partnered with another student who was going to design the software component. +
A couple weeks after they began their work on a first draft of the thesis proposal,
I heard of this idea for the first time. I was immediately fascinated by their project.
It was not only integration of the auditor with a potentially game like scenario,
but the complexities of recognizing people's movements, transmitting these actions
to a central point and then reacting to that information what caught my interest
as a programmer and tinkerer. So it comes as no surprise that when Mrs Fürndraht-Grossschopf's
original partner quit the project, I did not hesitate to jump on the opportunity
to work with her.



=== Initial project specification
The project's domain is a theatre like placement. The two major stakeholders, one
artist and the audience, consisting of several, possibly up to hundreds of members,
are placed opposite from each other. The listeners' seats are spread over several
rows facing mostly in the same direction towards the performer. She will prepare
beforehand a composition, prerecorded and split into separate tracks, one for the
basic theme and several instruments on their own. +
The basic theme will play in the background during the whole performance, whilst
the audience is able to control the influence selected instruments have on the aggregated
musical experience. The interface to communicate their intentions is a seat-occupancy-sensor.
By standing up or sitting down can they decide what should happen. +
During the live performance the artist primarily inhabits the role of conductor.
She first divides the people into different groups, each linked to a specific instrument.
The percentage of people standing in such a cluster directly influences how loud
an instrument plays. For example if 10 people of the guitar group consisting 20
in total were to stand up, would result in the guitar playing at 50 percent the
maximum volume. +
She further needs to explain to the audience how they are able to affect the rendition
and the role sectioning plays. In the beginning stages she will also direct the
rising and sitting to accustom the participants to the interaction and the system
as a whole. +
Later she might allow the people to freely create their own music by deciding the
active instruments  by themselves.



=== Related Works
This section describes related papers in the field of audience participation focusing
on practical implications and implementations.

Barkhuus and Jørgensen _[1]_ developed a 'cheering meter' to simplify the voting
procedure at rap competitions. Because of daily assembly and disassembly they deployed
their in Java written software on a laptop connected to 4 microphones pointed at
the audience. The captured sound was then analysed for peak levels of cheering and
the winner selected based on the highest registered value. Though utilising an entirely
different form of interaction, they share my sentiment of not using phones (text
  messages) and rely instead on a more physically involving type (cheering).

Paradiso et. Al _[2]_ examined the possibilities of giveaway wireless motion sensors.
The sensors transmit “as short pulse of RF energy” to a base station “whenever they
encounter a dynamic acceleration greater than a predetermined level”. With a very
small form factor (6.2 cm x 1.6 cm x 1.0 cm) and a weight of 5 grams they can be
easily held or worn. The low power consumption allows a 3V lithium coin cell battery
a operating time of 3 to 4 years of normal use (“assuming one event/week”). Though
the system seems to handle larger crowd of 200 people well, the transmission design
does not permit differentiation between different devices beyond a crude grouping
(here 3 groups) which has to be set at hardware level. +
The proposed responsive and dynamic music generation is in some ways similar to
our approach of using several tracks simultaneously. They however model continuous
activity in the form of dancing to five general activity levels, while we associate
a groups' state (standing/sitting) with instrument (track) volume. +
Thought the low cost and power consumption make for an intriguing design, the sensor
is not suited for our purposes. The grouping based on trimmer capacitors is too
inflexible and coarse. Further, it would have to be determined whether exceeding
a certain dynamic acceleration level is a sufficient indicator for activity 'standing up'
and 'sitting down'.

With massMobile Weitzner et al _[3]_ have created “a client-server system for mass
audience participation in live performances using smartphones”. Special focus was
put on ease of setup, development of additional use cases and deployment. To enable
multiple platform support, they utilise a web application executed in a phone's
browser connected to an API. +
The framework comes with its goals of “rapid deployment..plug-and-play deployment..
and simple use” close to my intentions for our project. Nonetheless there exists
room for improvement in regards to latency. By switching from the TCP based SOAP
to an UDP alternative could the network traffic be significantly reduced. For reason
which get explored more in depth below, I dislike the idea of mobile phones being
the primary form of input.


_[1] BARKHUUS, Louise; JØRGENSEN, Tobias. Engaging the crowd: studies of audience-performer interaction. In: CHI'08 extended abstracts on Human factors in computing systems. ACM, 2008._ +
_[2] PARADISO, Joseph A.; FELDMEIER, Mark. A compact, wireless, self-powered pushbutton controller. In: Ubicomp 2001: Ubiquitous Computing. Springer Berlin Heidelberg, 2001. S. 299-304._ +
_[3] WEITZNER, Nathan, et al. massMobile-an Audience Participation Framework. In: NIME. 2012. S. 21-23_ +



=== Goals
During the initial research I established fundamental properties the design should
incorporate:

First and foremost should the project be published under an open source license.
I have found that very few authors publish anything beyond the paper itself and
rarely make the accompanying code available. Nonetheless I believe it to be important
to share more than just the guiding principle behind an idea, but an implementation
as well. This makes it easier for others to both reproduce the described results
for themselves and enable them to experiment further with a minimum amount of prior
work. +
Easy of use should also be kept in mind. A framework only truly becomes practical
when it is convenient to set up and deploy. Likewise should the code be kept simple
and readable. +
Extendability is priority goal for this project. Although it is developed with a
specific use case in mind, it should be easy to add other scenarios to maximise
the benefit for others. This shall be achieved by clear and uniform interfaces allowing
mixing and extending as needed. If possible the components should not be too specialist
in their function, potentially freeing them of the context of this framework and
letting them be used in other projects. +
Having a fast feedback loop is important. After all it is not very rewarding if
you take an action and only 1 minute later happens something. The user can not effectively
asses the connection between her activity and the systems reaction. Furthermore,
if you have ever watched a video of a person speaking and the audio was offset even
by for example 50 ms - the difference was noticeable. It stands to reason that delays
might be as obvious in music, making latency and speed a crucial factor. On the
other hand is the process of standing up inherently imprecise. You have your inert
body to put into motion and at the same time are unaware at which point exactly
the seat sensor triggers. There is no individual feedback which would allow a person
to attempt to compensate for the delay. +
For this reasons a compromise is needed: Though design should consider speed, ideally
creating a realtime system, a margin of error (e.g. maximum of 1 second) shall be
allowed. This creates a leeway for the implementation and can account for the inaccuracy
of the interaction itself. +
The framework  should not have to handle millions of users at a time, relying
on technologies like load-balancers, but it should scale from an audience of only
a handful up to at least a hundred people. +
Several diverse reasons lead to the decision against the implementation of a mobile
phone based system. It is true that smartphones have become a wide spread, almost
ubiquitous commodity, but relying on them would potentially exclude some users with
e.g. older phones. Even when owning a brand new, top of the line smartphone, problems
may arise. A guest may arrive with an empty battery. The app may have a high power
consumption, leaving the phone completely discharged after the performance, resulting
in inconveniences and low customer satisfaction. +
Further the difficulty of supporting multiple mobile operating systems should be
considered. There exist solutions to cover different platforms with a single code
base (link:https://cordova.apache.org/[cordova]), but device API access and potential
performance limitations should be minded.
Another concern is the deployment method. Since installation should be as easy as
possible, using the platforms native app stores would be the straight forward and
preferred way. This however requires being part of a priced development program in
most cases (99 $ in link:https://developer.apple.com/support/compare-memberships/[Apple's case]),
which may not be cost-efficient in some use cases. +
Ideally should the technology to facilitate the interaction be as unintrusive and
unnoticeable as possible. +
Another important goal is affordability. To cater to a large and diverse developer
base including researches, students, etc. a tight budget should be assumed. Complicated
and expensive hardware should not be necessary to execute the software. Nor should
the seating state sensing require a pricey sensor.



=== Technology
==== Computing platform
As the basis for the occupancy sensor I chose a Raspberry Pi _[4]_. The Raspberry Pi
Foundation offers several different models ranging in price from the small Pi Zero
at 5$ up to the Pi 3 at 35$. The big advantage of a Pi over a simple micro-controller
like an Arduino is the ability to run a full-fledged operating system. These include
Windows IoT and Raspbian, a Debian-based custom system, developed and maintained
by the Foundation, which is what I selected. I decided on a Pi 2 because of the builtin
ethernet port and the 900 MHz quad-core ARM Cortex-A7 CPU suppling more than
enough computing power to run the sensor software.

_[4] https://www.raspberrypi.org/help/faqs/, last accessed 2016-04-15_


==== Sensing
To detect the actual person sitting in the chair, I settled on a force-sensitive
resistor. The relative low price, the easy and wide range of deployability
being the deciding factors. Dimensions of about 4,5cm x 4,5cm make it possible to place
it on any kind of chair whilst being hardly noticeable. To increase comfort and
simulate possible real world scenarios, I tried putting the sensor under a cushion.
My experiments have shown it to work regardless. This setup has the additional
benefit of hiding not only the sensor itself, but also the cable connecting to it. +
Although I was able to acquire such a sensor for about 10€ [5], there are even
cheaper alternatives. Nassar et al [6] have shown that such a sensor could be constructed from
everyday household objects with little effort. +
Since the Pi is not equipped with digital inputs, I needed an additional board to
transform the varying resistance of the sensor to binary inputs. Here I utilized
a little trick. The voltage level of the General Purpose Input & Output (GPIO) pins
are between 0 and 3.3 V maximum. The Pi however recognizes everything upwards of
1.3V as a logic 'HIGH'. The obvious solution was to use a voltage divider. I calculated
the second resistance (1000 Ohm) to pass the 1.3V at around 60% applied force. In my tests
this has proven to be remarkable reliable. +
I further built 2 boards which are able to use 4 and 5 force sensitive resistors
simultaneously. Since each sensor only requires only one GPIO pin to work,
a single Pi would be able to support over 15 FSRs. However every sensor needs to
be connected to the board. Increased cable length also potentially increases power
consumption and complexity of the cable management. So to not overtax the Pi's limited
power capabilities, I limited the number of available connections on the board.
I recommend using an uneven number and place the small computer with the
middle seat. The cables can then be run to either side.

_[5] http://www.amazon.de/gp/product/B004R277AS/, last accessed 2016-04-15_
_[6] NASSAR, Joanna M., et al. Paper Skin Multisensory Platform for Simultaneous Environmental Monitoring. Advanced Materials Technologies, 2016._


==== Name
The name of the core python software is based on the project title *paps*
(*P* i-based *A* udience *P* articipation *S* ystem). However if you
are not going to use a Raspberry Pi in your project, *paps* once more applies
(*P* ython-based *A* udience *P* articipation *S* ystem). If you want to go even
further and for example use only the interfaces and/or the network protocol, *paps*
still works (*P* articipation  *S* ystem). +




== Installing
=== Environment
All the code is writing in python 2, specifically 2.7. I have taken some first steps
to support python 3 as well, but at this point it probably will not work yet. +
Tough I have been developing mostly under windows, it has been tested to some degree
on other platforms (OSX, Raspbian) too.



=== Basic installs
The first thing you need is a working python environment:

* Install the latest version of link:https://www.python.org/downloads/[python 2.7]
* Install/get the latest version of link:https://pip.pypa.io/en/stable/installing/[pip]

.RECOMMENDED
[NOTE]
I recommend working on and running your code in a virtual environment. +
You can use link:https://virtualenv.pypa.io/en/latest/[virtualenv]



=== Paps install
==== PyPI
If you want to use paps in your own project, it is available from link:https://pypi.python.org/pypi[PyPI]. +
Simply install it via `pip install paps` or add paps to your requirements file.


==== Manuel
Get the latest version from github and simply run `python setup.py install`. That
installs every dependency and you are good to go.



=== Paps development
If you want to work on paps and develop it further, use the `Manuel` installation
method, but change `python setup.py install` to `python setup.py develop`. That
way any changes you make take immediate effect. I also recommend installing the
development-dependencies ( `pip install -r dev-requirements.txt`. +
Finally don't forget to send me a pull request.




== System
=== Core concepts
==== Person
Although paps was developed in the context of a musical project, it is designed
as a general audience participation framework, not limited to a single use case. +
Naturally the core entity used throughout the system is creatively called `Person`.
It represents an audience member and its current state. +
At this point a Person only has two properties, an id and a field to indicate whether
the represented individual is standing up or sitting down. However as long as all
the transform functions (to_/from_dict, to_/from_bits,..) in
link:https://github.com/the01/python-paps/blob/master/paps/person.py[person.py]
are changed, paps itself should continue to work as expected (the sensorServer might
need a few adjustments). Keep in mind that not every plugin (see later) might be
as lenient in the type of Person it can work with.


==== Flotils
Most classes inherit in one way or the other from the link:https://github.com/the01/python-flotils[flotils]
package. Most notable are the `Logable` and `StartStopable` classes. `Logable` adds
logging capabilities to an instance (as best demonstrated on the above git page).
'StartStopable', as the name suggests, provides methods to start and stop a class
instance. Calling start with True as the parameter is blocking, which means it will
only return after stop has been executed. Additionally it provides a boolean variable
indicating its current state (running or not).


==== ChangeInterface
The other core concept besides a Person is the
link:https://github.com/the01/python-paps/blob/master/paps/changeInterface.py[`ChangeInterface`].
It represents the most generic actions a person can take

* *on_person_new*: This occurs when a person has just joined the audience. In other
words she was not known to the receiving component before.
* *on_person_update*: The state of a person has actually changed. (No person for
  whom that is not true should not be included here)
* *on_person_leave*: A person has left the audience and should not be considered
from this moment on.

The ChangeInterface is mostly used at borders between different layers of the system
(physical sensors detecting actual humans, the SensorServer receiving events from
clients, the CrowdController forwarding changes, ..). +
It is recommended to use/implement whenever Person information needs to be exchanged.



=== Crowd
Crowd represents the highest level of the paps framework. All lower levels are responsible
for people recognition (data acquisition), transmission and management. This stage
is where the audience participation actually takes place. +


==== Plugin
The plugin is the component that accomplishes exactly that. Here you would
write the code for your base-performance and react to changes/movement in your audience. +
One possible plugin could implement the logic for musical chairs. You would place
sensors on every seat and the plugin would start playing music. At some random point
the music would stop and the last one left standing would be eliminated. You could even
have a ranking or statistics on who was the fastest to sit down. +
A plugin can be run since it inherits from StartStopable and receives information
about the audience by implementing the ChangeInterface. +
Additionally a `controller` property is present, which is `None` by default, except
when executed by a CrowdController (see next part). +
Because it is able to receive change-events, it is possible to directly put a plugin
on top of a sensor, bypassing network components (see SensorInterface). +
When writing a plugin one should keep in mind that method invocations might block
the calling code. For example time spent inside `on_person_update` should be kept
as short as possible, otherwise the sensor or server might miss updates on the audience's
state.


==== CrowdController
In practice it is a good idea for classes between different layers to be loosely-coupled.
An instance wanting to emit change-events should only have to use a ChangeInterface.
But that means one were only able to use a single plugin at the same time. On the other
hand it could utilize multiple ChangeInterface-objects, but would also have to
implement management code for all those instances, which would unnecessarily complicate
the class. +
That is where the CrowdController comes in. It has a `plugins` property, where multiple
plugins can be registered and since CrowdController is a subclass of Plugin, it can
be used everywhere you would normally use a plugin (or ChangeInterface for that
matter). Every method call on the controller is forwarded to each plugin, including
`stop()` and `start()` (which is where the plugin's `controller` property is set). +
The recommendation about keeping execution time short becomes especially critical
when using a CrowdController with multiple plugins. It would be possible to dispatch
all method-forwards to their own thread. Currently the controller only iterates
through the plugins, sequentially calling the methods. As a result the sensor/server
gets blocked for the sum of the individual execution durations. Even if your
plugin returns in 0.2 seconds, using 5 such plugins simultaneously would still result
in a time lag of a whole second.



=== Communication
The first step was to decide how the different sensors would be communicating with
the server. Ease of installation and avoiding extra components being primary concerns,
I decided on LAN. (Almost) all Raspberry Pis come equipped with an ethernet port.
This was before the Pi 3 was announced on February 29th 2016, which offers onboard
WIFI as well as Bluetooth. I would have still settled on LAN, because of the higher
transfer rates and stability. +
The downside of course being, that now every sensor has to be connected to the
network via cable. On the other hand one could eliminate the power cable by using
power over ethernet (PoE).


==== SensorInterface (si)
The sensor interface is responsible for connecting sensors monitoring the actual
people in the audience to the plugin(s) running the participation related code.
An implementation should link the two parts of the interface (client/server) together
(for example over LAN). +
It is recommended for sensors to propagate their information to an other object
by use of the ChangeInterface. That way, when testing or using a simple setup, a
user can connect a plugin or CrowdController  directly to the sensor and does not
have to go through a network component first. +
An example of such an sensor has been provided with paps and can be found in the
link:https://github.com/the01/python-paps/blob/master/examples/gpio_detector.py[example directory].
This GPIODetector monitors specified GPIO pins on a Raspberry Pi for changes, where
a set pin (HIGH) represents a sitting and an unset (LOW) pin a standing person. +
The example further demonstrates how to save/load a configuration from a file with
the main focus being the device id (see APP in the next chapter) and how to connect
a sensor to the SensorInterface (SensorClientInterface).

===== SensorClientInterface
The SensorClientInterface is heavily inspired by the ChangeInterface, but amended
with remote configuration capabilities. Its `config` method should be implemented
to allow the server to alter  local settings (potentially including higher layers,
that use the SensorClientInterface). +
Though still holding much of the same meaning, the on_person-events have been renamed
for this interface.

* on_person_new ≈ join
* on_person_leave ≈ unjoin
* on_person_update ≈ person_update

This decision was taken deliberately for two reason. The ChangeInterface's methods
are passive, that is to say, you receive information. The SensorClient's on the
other hand are active. You tell someone else that something has changed. Secondly
this was chosen to reflect the different scale. The communication between SensorClient
and SensorServer is meant to bring the state-information of the whole audience together.
You are not only detecting a new person, but rather a new person has joined the
audience.

===== SensorServerInterface
The SensorClientInterface's counterpart is responsible for translating the incoming
information back into change-events. It takes a `change` argument in its constructor
that has to implement the  ChangeInterface and will receive the events.

===== SensorServerClientAdapter
Since connecting a sensor to a SensorClientInterface implementation is probably
a very frequent task, paps has such an adapter already built in. Give the SensorClientAdapter
an instance of a  SensorClientInterface and then plug the adapter (it implements
the ChangeInterface) into your sensor and it will translate change-events into
SensorInterface-actions.


==== Audience Participation Protocol (APP)
Keeping the project goals in mind and wanting to keep the network traffic as low
as possible, I decided to design my own protocol. +
TCP as the basis would be easy. It guaranties reliable, correct and ordered packet
delivery. Definitely good properties for a protocol to have. +
Since People coming/leaving (in the context of ChangeInterface) only happens at
the beginning/end, most of the traffic will consist of update events. Keeping hundreds
of TCP connections (and sockets) open for that single purpose seems unpractical. +
So I opted for a UDP-based protocol.

The protocol uses big-endian encoding.

===== APP Header
image:docs/appheader.svg[]

*Protocol field* (C Type): Description of field

*Version* (unsigned char)
*Maj Ver* (nibble): Major part of protocol version

*Min Ver* (nibble): Minor part of protocol version

*MsgType* (unsigned char): Message Type/type of packet

* 0: (ACK) Empty packet - only acknowledging packet
* 1: JOIN-Packet
* 2: CONFIG-Packet
* 3: UNJOIN-Packet
* 4: UPDATE-Packet
* 5: DATA-Packet

*Payload Length* (unsigned short): Length of the payload (in bytes)

*Timestamp* (float): Unix timestamp of packet creation/transmit time

*Device Id* (unsigned short): Device id of sender.

* 0: (REQUEST) Request a new id from server
* 1: (SERVER) Id of a server.
* 2-65536: Possible client id

*Flags* (unsigned short): Set flags. To use several in the same packet either add
the values or do a bit-wise or.

* 1: (SEQ) Is a sequence number present
* 2: (ACKSEQ) Is an acknowledged sequence number present

*Sequence Number* (optional)(unsigned int): Sequence number of packet. If present,
SEQ flag has to be set. If present, requires an ACK to be sent. +
By using this you can ensure packet delivery.

*ACK Sequence Number* (optional)(unsigned int): Acknowledge for packet with this
Sequence Number. If present, ACKSEQ flag has to be set. +
A dedicated ACK-Packet is not needed. By setting this field, any packet can become
an ACK-Packet.

*Payload* (Payload Length number of bytes): Payload content is dependent on the
type of packet/message being transmitted

===== APP JOIN Message
Message to join the local audience and comparable to `ChangeInterface.on_person_new`.
This can be sent to the server directly or, to enable auto-discovery capabilities,
to a multicast group (Recommended: 239.255.136.245). Of course a server first has
to make a membership request for that group. +
The payload consists of a string with a json object containing all information
required to join the audience. The absolute minimum is a field `people` with an
array of the people (Person) this client offers as a json object (python dict)
encoded (see following code). Additional fields may be added as needed, but are
not part of the APP specification. +
APP requires that all the people have to be announced at join-time. If you want
to add people at a later point, unjoin first and then re-join with the updated
people list. +
The `device id` field of the header may be either set to REQUEST (0) or to a valid
client id (2-65536). Providing a client id much like with dhcp only serves as a
request for that id, the server can choose to assign a different one. The logic
on how to handle id collisions and to identify clients between runs is left to the
concrete implementation. Though some possible approaches could involve MAC-addresses
or issuing unique ids.

[source, json]
----
  {
    "people":[Object representation of Person]
  }
----

Requires an ACK-Packet to be sent.

===== APP CONFIG Message
Message to change the configuration (of a client). +
The payload consists of a string with a json object containing all configuration
changes. If a settings parameter is not present, it should not be changed. +
The parameter names can be chosen freely (in accordance with json), except for these
reserved ones:

* device_id: New device id assigned to this client
* server_ip: The IP where the server can be reached. (Auto-discovery over multicast is deeply integrated into APP -  though not required)
* server_port: The port where the server can be reached.

Requires an ACK-Packet to be sent.

===== APP UNJOIN Message
Message to leave to local audience and comparable to `ChangeInterface.on_person_leave`. +
Informs the server that all people associated with this client are leaving the audience. +
This packet does not have any kind of payload, which means the server has to keep
track of who (people) are registered with this client.

Requires an ACK-Packet to be sent.

===== APP UPDATE Message
Message to update the state of people and comparable to `ChangeInterface.on_person_update`. +
Since this is most likely the most (concurrently) sent packet, most of speed and
size considerations were taken here. It does NOT require an ACK-Packet to be sent,
cutting the number of packets in halve. However the basis for APP is still UDP,
so packet loss is a possibility. To address this, every UPDATE message needs to
contain the state of ALL people being monitored by this client. This reduces the
chance of lost information especially under the following assumptions:

. A single client monitors not just one person, but multiple.
. People seated closely together, move together. If the person next to you stands
  up, you are likely to move as well.
. People are placed together in few groups.
. It only matters for a group how *many* people are in a certain state, not which
  ones.

Following these assumptions, consider this thought experiment: +
You and the two people sitting to your left and your right are in the same group
(your actions have the same result), as well as your seat sensors being connected
to the same client (Raspberry Pi) [assumption 1]. Lets visualize that state in the
following way
*[seated, seated, seated]*. Now the person on your left stands up, changing the
simple overview to *[standing, seated, seated]* and triggering the client to send
this change to the server. Next you and then your other neighbour stand up
(not necessarily because of herd mentality, but maybe the conductor has told your
group to stand up) [assumption 2], the state changes to *[standing, standing, seated]*
and finally *[standing, standing, standing]*. These changes also get transmitted
to the server. +
Even if the first two packets in this scenario were lost, as soon as the third arrived
at the server, it would have the complete and correct state of your group (at least
the ones connected to your client). It would get that information a little
later, but we have cut the traffic by 5 packets (1 x resent UPDATE-packet
& 1 x ACK-Packet for each of the two lost packets + 1 x ACK-packet for the last
UPDATE that did not get lost) +
If however the first and last packets were lost, then the information about your
right neighbour standing up would not have reached the server. +
But if you consider that UDP-packets are more likely to be dropped with

.. bigger packet sizes +
.. more packets on the network

you can look at strategies to decrease the chances/impact. +
Lets consider b). More packets mean more people (updates), which also means either
packet loss is less/not very likely or we have many people. We do not have a problem
in the first case and in the second only a few people will have wrong state
information (see example scenario above). Because of [assumption 3] group sizes
will be big, but because of that and [assumption 4] a single (or few) person being
misrepresented will not have much negative impact on the group as a whole. +
a) is also being addressed by APP. A person implements transformation functions
to and from a bit-representation. Currently this only consists of the sitting-state: +
`0` = is not sitting; `1` = is sitting. +
Since the UPDATE-packet requires the state of all people be present in the payload,
 the device id can be omitted, but the same order as in the JOIN-packet has to be
 kept to still be able to identify each person. +
The bit-representation then gets packed into bytes and the information start indicated
by a marker (`1`) +

====== Examples
`P(0,sit)` means a Person with id = 0 is sitting +
`P(1,!sit)` means a Person with id = 1 is not sitting

|===
|Name of Column 1 |Bit representation |Hex representation

|`P(0,!sit)`
|10
|0x02

|`P(1,!sit)`
|10
|0x02

|`P(0,sit)`
|11
|0x03

|`P(0,!sit);P(1,sit)`
|101
|0x05

|`P(0,!sit);P(1,!sit);P(2,sit);P(3,!sit);P(4,sit);P(5,!sit);P(6,sit)`
|1001 0101
|0x95

|`P(0,!sit);P(1,!sit);P(2,sit);P(3,!sit);P(4,sit);P(5,!sit);P(6,sit);P(7,sit)`
|1 0010 1011
|0x012b
|===

===== APP DATA Message
A DATA message enables the protocol to transmit data as a json encoded
string.

Requires an ACK-Packet to be sent.

== Conclusion
The well documented and commented source code allows results in good readability.
Someone familiar with the general components of paps and/or this document, but new
to the codebase itself should be able to understand the different parts quickly
and start developing without any difficulties. The python programming language,
which except for a few peculiarities allows for a straightforward way to write code,
further aids this. +
The server autodiscovery of the audience participation protocol in combination with
the ability to save runtime settings between executions (such as the device id) as
demonstrated in GPIODetector make deployment even to a large number of sensors easy.
Only a single SD card needs to be prepared where the software is set to automatically
run at boot-time and the seats need to be allocated to the specific groups only once.
Though the interface was the designed to run in a web browser so that it is possible
to control the system from a variety of devices, including tablets, the sorting
remains a tedious errand. It remains a demonstration implementation, showing one
possible way of approaching this task and will mostly likely prove to work best
only with few people. Identifying which physical sensor corresponds to a person
in the interface has to be achieved by manually triggering the sensor. Of course
this method does not scale well to an audience size of hundreds of people. But since
it is only required to be done once, it might be considered an acceptable complication. +
The uniform interfaces, especially `ChangeInterface` makes for a very modular implementation,
allowing to freely combine different parts of the application (e.g. using a plugin
with or without a CrowdController, placing a plugin directly on top of a sensor,
etc.). Additionally the design of the APP enables the developer to easily connect
to the included `SensorServer` from her own modules and even different programming
languages. But it was designed with a certain environment and simplicity in mind.
A closed off network only for APP devices, with no malicious clients and no or
at least next to none other traffic. The result is a very naïve protocol with
few or no control, authentication or security features built in. It is also very
susceptible to tampering (intentional and unintentional) and potential denial of
service attacks. That is adequate according to our predefined constraints, but should
be kept in mind when actually deploying a system. +
After some fine tuning the sensor performed remarkable well, even under more elaborate
setups like placing a pillow on top of it. The Raspberry Pi was a good decision as
an operating platform, both in price and in functionality. It provides more than
enough computing power for this task and should be able to handle plugin execution
as well. Nevertheless it might not be suited for this task in all situations. In
tests I was only able to record a frequency of 200 to 240 update packets per second.
The software itself has however proven to be capable of handling over 400 packets
per second continuously. During these stress test over several (between 5 and 30)
minutes I recorded hardly any packet loss, indicating APP's resilience might have
been overengineering. Moreover this shows the sufficient speed of the system, although
improvements could be easily achieved by benchmarking the current code, optimising
slow sections or even implementing components in C. +
Additionally to its versatility adheres the Pi with a price tag of 35$ to the goal
of affordability. By connecting multiple sensors to a single computer further reduces
the per seat price, making the force sensitive resistor at around 10€ the most expensive
component. However research has shown that it is possible to construct a force sensor
from everyday household items, likely reducing costs. Since the board to connect the
Pi and sensors consists mostly of resistors, it should be constructible for little
money too.

With my work I was able to create an application, both in hardware as in software,
letting audience members influence the execution of prerecorded music and change
the volume and dominance of specific instruments. I further built a core framework
for general audience participation, laying a foundation for different interaction
methods. +
This system moreover satisfies all set design goals within their constraints, including
performance, construction cost, modularity and manageability.


== How to
include::docs/write_plugin.adoc[leveloffset=+2]
